{% extends "layout.html" %}

{% block body %}
<div class="model-container">
    <h1 class="model-title">Classical Machine Learning Models</h1>
    <div class="model-cards">
        <div class="model-card">
            <a href="https://dl.acm.org/doi/10.1145/335191.335388" target="_blank"><h3>Local Outlier Factor</h3></a>
            <div class="model-front">
                <img src="static/images/lof.png" alt="">
            </div>
            <div class="model-back">
                <p>The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors.</p>
            </div>
        </div>
        <div class="model-card">
            <a href="https://ieeexplore.ieee.org/abstract/document/4781136" target="_blank"><h3>Isolation Forest</h3></a>
            <div class="model-front">
                <img src="static/images/iforest.png" alt="">
            </div>
            <div class="model-back">
                <p>Isolation Forest is an ensemble-based unsupervised algorithm for anomaly detection. It isolates anomalies by constructing decision trees and averaging their predictions, without requiring a predefined notion of 'normal' data. This approach offers a robust and efficient method for identifying outliers in datasets.</p>
            </div>
        </div>
        <div class="model-card">
            <a href="https://aiblog.co.za/technology/elliptic-envelope-anomaly-detection" target="_blank"><h3>Elliptic Envelope</h3></a>
            <div class="model-front">
                <img src="static/images/elliptic.png" alt="">
            </div>
            <div class="model-back">
                <p>Elliptic Envelope is a statistical anomaly detection method designed for multivariate data presumed to follow a normal distribution. By fitting an ellipse to central data points, outliers outside this boundary are flagged as potential anomalies, making it robust for applications like fraud or network intrusion detection, especially when data adheres to Gaussian assumptions.</p>
            </div>
        </div>
    </div>
    <h1 class="model-title">Deep Learning Models</h1>
    <div class="model-cards">
        <div class="model-card">
            <a href="https://dl.acm.org/doi/abs/10.1145/3422622" target="_blank"><h3>GAN</h3></a>
            <div class="model-front">
                <img src="static/images/gan.jpeg" alt="">
            </div>
            <div class="model-back">
                <p>Generative Adversarial Networks (GANs) employ two models, a generator (G) and a discriminator (D), in a minimax game to capture and distinguish data distribution respectively. G is trained to maximize D's error, resulting in G recovering the training data distribution while D approaches 1/2 accuracy. With multilayer perceptrons defining G and D, the system is trainable via backpropagation.</p>
            </div>
        </div>
        <div class="model-card">
            <a href="https://dl.acm.org/doi/abs/10.1145/3097983.3098052" target="_blank"><h3>AutoEncoders</h3></a><div class="model-front">
                <img src="static/images/autoencoders.png" alt="">
            </div>
            <div class="model-back">
                <p>Autoencoders is a neural network variant which excel in unsupervised tasks like anomaly detection. By compressing and reconstructing data, they learn normal patterns through minimizing reconstruction errors. Adaptable to diverse anomaly severities, enhancements like convolutional layers bolster their proficiency in capturing and identifying deviations, rendering autoencoders a potent tool for anomaly detection in unlabeled datasets.</p>
            </div>
        </div>
        <div class="model-card">
            <a href="https://openreview.net/forum?id=BJJLHbb0-" target="_blank"><h3>DAGMM</h3></a>
            <div class="model-front">
                <img src="static/images/dagmm.png" alt="">
            </div>
            <div class="model-back">
                <p>Deep Autoencoding Gaussian Mixture Model (DAGMM) integrates deep autoencoder design with Gaussian mixture modeling for anomaly detection. By concurrently reconstructing data and estimating latent space density, DAGMM identifies anomalies as points with low probability, enabling unsupervised detection across domains. DAGMM's ability to detect anomalies without labeled data renders it valuable for diverse unsupervised anomaly detection tasks.</p>
            </div>
        </div>
        <div class="model-card">
            <a href="https://ieeexplore.ieee.org/abstract/document/8836638" target="_blank"><h3>LSTM</h3></a>
            <div class="model-front">
                <img src="static/images/lstm.png" alt="">
            </div>
            <div class="model-back">
                <p>Long Short-Term Memory (LSTM) networks is a form of recurrent neural network, specialize in capturing temporal dependencies, ideal for time-series anomaly detection. By training on normal sequences and detecting significant deviations from predicted values, LSTMs excel in recognizing anomalies. Widely applicable in finance, cybersecurity, and industrial monitoring, LSTMs are valued for their capacity to discern complex patterns in sequential data.</p>
            </div>
        </div>
        <div class="model-card">
            <a href="https://link.springer.com/article/10.1007/s42979-021-00866-4" target="_blank"><h3>Quantile Regression</h3></a>
            <div class="model-front">
                <img src="static/images/qreg.png" alt="">
            </div>
            <div class="model-back">
                <p>Quantile regression for anomaly detection models conditional quantiles, enabling outlier detection. By comparing predicted quantiles with actual observations, it captures anomalies often missed by mean-based methods. This versatile approach offers flexibility across domains by focusing on specific quantiles relevant to the application.</p>
            </div>
        </div>
    </div>
    <h1 class="model-title">Tree Based Models</h1>
    <div class="model-cards">
        <div class="model-card">
            <a href="https://link.springer.com/article/10.1007/s10489-022-03940-3" target="_blank"><h3>MG Tree</h3></a>
            <div class="model-front">
                <img src="/static/images/mgbtai.png" alt="">
            </div>
            <div class="model-back">
                <p>MGTree, a multi-generations binary tree approach, tackles false alarms in industrial anomaly detection. Effective on large and small datasets, it outperforms iForest, OCSVM, and Elliptic Envelope in correctly identifying anomalies. Applied across various industrial datasets like Yahoo, AWS, and machine sensors, MGTree proves its efficacy in empirical evaluations.</p>
            </div>
        </div>
        <div class="model-card">
            <a href="https://link.springer.com/chapter/10.1007/978-3-030-79463-7_44" target="_blank"><h3>D-BTAI</h3></a>
            <div class="model-front">
                <img src="/static/images/bat.png" alt="">
            </div>
            <div class="model-back">
                <p>The D-BTAI algorithm combines Binary Anomaly Trees (BAT) and ECBLOF for industrial anomaly detection. It constructs a tree from input data clusters, identifying anomalies at leaf nodes meeting specific conditions. Anomalies are determined by normalized ECBLOF scores, with selection based on both clustering and score deviation.</p>
            </div>
        </div>
    </div>
</div>
{% endblock %}